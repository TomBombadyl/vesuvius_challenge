{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vesuvius Challenge - Surface Detection Submission\n",
    "\n",
    "This notebook performs surface segmentation on 3D CT scans and generates submission.zip.\n",
    "\n",
    "## Pipeline\n",
    "1. Load pre-trained ResidualUNet3D model\n",
    "2. Load test volumes (3D CT scans)\n",
    "3. Run sliding window inference\n",
    "4. Apply post-processing\n",
    "5. Save 3D binary masks as .tif files\n",
    "6. Create submission.zip\n",
    "\n",
    "**Output:** submission.zip with [image_id].tif files (3D uint8 binary masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tifffile\n",
    "\n",
    "# Add src to path\n",
    "if Path('src').exists():\n",
    "    sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "from src.vesuvius.models import build_model\n",
    "from src.vesuvius.infer import sliding_window_predict\n",
    "from src.vesuvius.postprocess import apply_postprocessing\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (update for Kaggle environment)\n",
    "DATA_ROOT = Path('/kaggle/input/vesuvius-challenge-surface-detection')\n",
    "# DATA_ROOT = Path('vesuvius_kaggle_data')  # Local testing\n",
    "\n",
    "MODEL_PATH = Path('/kaggle/input/vesuvius-model-weights/last_exp001.pt')\n",
    "# MODEL_PATH = Path('checkpoints/last_exp001.pt')  # Local testing\n",
    "\n",
    "OUTPUT_DIR = Path('.')  # Kaggle working directory\n",
    "\n",
    "# Model config\n",
    "MODEL_CONFIG = {\n",
    "    'type': 'unet3d_residual',\n",
    "    'in_channels': 1,\n",
    "    'out_channels': 1,\n",
    "    'base_channels': 40,\n",
    "    'channel_multipliers': [1, 2, 2, 4, 4],\n",
    "    'blocks_per_stage': 3,\n",
    "    'deep_supervision': True,\n",
    "    'dropout': 0.15,\n",
    "    'activation': 'mish',\n",
    "    'norm': 'instance'\n",
    "}\n",
    "\n",
    "# Inference config\n",
    "INFERENCE_CONFIG = {\n",
    "    'patch_size': [64, 128, 128],\n",
    "    'overlap': [32, 96, 96],\n",
    "    'gaussian_blend_sigma': 0.125,\n",
    "    'tta': 'none',  # Set to 'flips' for better accuracy (slower)\n",
    "    'threshold': 0.42,\n",
    "}\n",
    "\n",
    "# Post-processing config\n",
    "POSTPROCESS_CONFIG = {\n",
    "    'remove_small_components_voxels': 600,\n",
    "    'fill_holes': False,\n",
    "    'closing_radius': 3\n",
    "}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"Model: {MODEL_PATH}\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading model...\")\n",
    "model = build_model(MODEL_CONFIG)\n",
    "\n",
    "checkpoint = torch.load(MODEL_PATH, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"✓ Model loaded: {num_params/1e6:.1f}M parameters\")\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(1, 1, *INFERENCE_CONFIG['patch_size']).to(DEVICE)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"✓ Test pass: {test_input.shape} -> {test_output['logits'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test.csv\n",
    "test_csv = DATA_ROOT / 'test.csv'\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "# Get test image IDs\n",
    "test_ids = test_df['Id'].astype(str).tolist()\n",
    "\n",
    "print(f\"Found {len(test_ids)} test volumes:\")\n",
    "for test_id in test_ids:\n",
    "    print(f\"  - {test_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_volume(image_id: str) -> np.ndarray:\n",
    "    \"\"\"Load 3D test volume.\"\"\"\n",
    "    volume_path = DATA_ROOT / 'test_images' / f\"{image_id}.tif\"\n",
    "    \n",
    "    if not volume_path.exists():\n",
    "        raise FileNotFoundError(f\"Volume not found: {volume_path}\")\n",
    "    \n",
    "    volume = tifffile.imread(str(volume_path))\n",
    "    return volume\n",
    "\n",
    "\n",
    "def normalize_volume(volume: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normalize to [0, 1].\"\"\"\n",
    "    vmin, vmax = volume.min(), volume.max()\n",
    "    if vmax > vmin:\n",
    "        volume = (volume - vmin) / (vmax - vmin)\n",
    "    return volume.astype(np.float32)\n",
    "\n",
    "\n",
    "def predict_volume(image_id: str) -> np.ndarray:\n",
    "    \"\"\"Run inference on single volume.\"\"\"\n",
    "    print(f\"\\nProcessing {image_id}...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    # Load and normalize\n",
    "    volume = load_test_volume(image_id)\n",
    "    print(f\"  Volume: {volume.shape}, {volume.dtype}\")\n",
    "    \n",
    "    volume = normalize_volume(volume)\n",
    "    volume_tensor = torch.from_numpy(volume[None, None, ...])\n",
    "    \n",
    "    # Inference\n",
    "    print(f\"  Running inference...\")\n",
    "    with torch.no_grad():\n",
    "        pred = sliding_window_predict(model, volume_tensor, INFERENCE_CONFIG, DEVICE)\n",
    "    \n",
    "    # Binarize\n",
    "    threshold = INFERENCE_CONFIG['threshold']\n",
    "    binary_mask = (pred >= threshold).astype(np.uint8)\n",
    "    \n",
    "    # Post-process\n",
    "    binary_mask = apply_postprocessing(binary_mask, POSTPROCESS_CONFIG)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    coverage = binary_mask.sum() / binary_mask.size * 100\n",
    "    print(f\"  ✓ Done in {elapsed:.1f}s | Coverage: {coverage:.2f}%\")\n",
    "    \n",
    "    return binary_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Inference on All Test Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Running inference on test volumes\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "predictions = {}\n",
    "total_start = time.time()\n",
    "\n",
    "for image_id in test_ids:\n",
    "    try:\n",
    "        mask_3d = predict_volume(image_id)\n",
    "        predictions[image_id] = mask_3d\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "        raise\n",
    "\n",
    "total_elapsed = time.time() - total_start\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"✓ Inference complete: {total_elapsed/60:.1f} minutes\")\n",
    "print(f\"✓ Processed {len(predictions)} volumes\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Submission ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating submission.zip...\")\n",
    "\n",
    "submission_path = OUTPUT_DIR / 'submission.zip'\n",
    "\n",
    "with zipfile.ZipFile(submission_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "    for image_id, mask_3d in predictions.items():\n",
    "        # Save as temporary TIFF\n",
    "        temp_path = f'{image_id}.tif'\n",
    "        tifffile.imwrite(temp_path, mask_3d.astype(np.uint8))\n",
    "        \n",
    "        # Add to ZIP\n",
    "        zf.write(temp_path, arcname=f'{image_id}.tif')\n",
    "        \n",
    "        # Clean up\n",
    "        Path(temp_path).unlink()\n",
    "        \n",
    "        print(f\"  ✓ Added {image_id}.tif to ZIP\")\n",
    "\n",
    "zip_size = submission_path.stat().st_size / (1024 * 1024)\n",
    "print(f\"\\n✓ Created submission.zip ({zip_size:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValidating submission...\")\n",
    "\n",
    "with zipfile.ZipFile(submission_path, 'r') as zf:\n",
    "    files = zf.namelist()\n",
    "    print(f\"Files in ZIP: {len(files)}\")\n",
    "    \n",
    "    for filename in files:\n",
    "        # Read and validate\n",
    "        with zf.open(filename) as f:\n",
    "            import io\n",
    "            mask = tifffile.imread(io.BytesIO(f.read()))\n",
    "            \n",
    "            print(f\"  ✓ {filename}: {mask.shape}, {mask.dtype}, \"\n",
    "                  f\"{mask.sum()/mask.size*100:.1f}% coverage\")\n",
    "            \n",
    "            # Validate format\n",
    "            assert mask.dtype == np.uint8, f\"Wrong dtype: {mask.dtype}\"\n",
    "            assert mask.ndim == 3, f\"Must be 3D, got {mask.ndim}D\"\n",
    "            assert np.all((mask == 0) | (mask == 1)), \"Must be binary (0 or 1)\"\n",
    "\n",
    "print(\"\\n✓ Validation passed!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"✓ SUBMISSION READY\")\n",
    "print(f\"✓ File: {submission_path}\")\n",
    "print(f\"✓ Size: {zip_size:.1f} MB\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
